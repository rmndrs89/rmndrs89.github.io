{
  "hash": "e5a29bbb2524961818dd001e496c27f7",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Digit recognizer\"\ndescription: |\n  Recognizing handwritten digits with a convolutional neural network.\ndate: 2025-11-17\ncategories: [Python, PyTorch]\ncode-fold: true\ncode-copy: true\n---\n\n\n::: {.callout-note}\n## Abstract\n\nThe problem with handwritten digits.\n:::\n\n::: {#cell-fig-example-images .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torchvision\nfrom torchvision import datasets, transforms\n\n# Define the data transforms\ndata_transforms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n])\n\n# Get the MNIST dataset\nROOT_PATH = \"~/Datasets/PyTorch\"\ntrain_dataset = torchvision.datasets.MNIST(root=ROOT_PATH, train=True, transform=data_transforms, download=True)\ntest_dataset = torchvision.datasets.MNIST(root=ROOT_PATH, train=False, transform=data_transforms, download=True)\n\n# Define the dataloaders\nBATCH_SIZE = 64\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n# Visualize images\nfor example_images, example_labels in train_loader:\n    break\nnum_cols = 8\nnum_rows = int(example_images.shape[0] // num_cols)\nfig, axs = plt.subplots(num_rows, num_cols, figsize=(5, 5))\nfig.subplots_adjust(wspace=0.05, hspace=0.05)\nfor example_idx in range(example_images.shape[0]):\n    ax = axs[example_idx % num_cols, example_idx // num_cols]\n    ax.imshow(example_images[example_idx].squeeze(), cmap=\"gray\")\n    ax.axis(\"off\")\n# plt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![A batch of example images of handwritten digits.](index_files/figure-html/fig-example-images-output-1.png){#fig-example-images}\n:::\n:::\n\n\n## Build a model\n\nWe start off with building a baseline model that simply takes all individual pixels and passes them through a fully connected network.\n\n::: {#9b633c53 .cell execution_count=2}\n``` {.python .cell-code}\nclass BaselineModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.flatten = nn.Flatten()\n        self.linear1 = nn.Linear(in_features=28 * 28, out_features=16)\n        self.linear2 = nn.Linear(in_features=16, out_features=10)\n\n    def forward(self, x):\n        x = self.flatten(x)\n        x = F.relu(self.linear1(x))\n        x = self.linear2(x)\n        return x\n```\n:::\n\n\n## Train the model\n\nIn `PyTorch` we need to make sure that the model and data live on the same device. Obviously, if we can use a GPU to speed up the training, we would do this. Therefore, we first check for the device, and then move the model and data there.\n\n::: {#c6788e0a .cell execution_count=3}\n``` {.python .cell-code}\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Create an instance of the model\nbaseline_model = BaselineModel().to(device)\n\n# Define the loss function to use\nloss_fn = nn.CrossEntropyLoss()\n\n# Use a common optimizer\noptimizer = optim.Adam(baseline_model.parameters(), lr=0.001)\n```\n:::\n\n\nWe define a separate function for validation that we can call after each training epoch:\n\n::: {#e814b8bc .cell execution_count=4}\n``` {.python .cell-code}\ndef eval_step(\n    model: nn.Module,\n    dataloader: DataLoader,\n    loss_fn: nn.Module,\n    device: torch.device\n):\n    # Put the model in eval mode\n    model.eval()\n\n    # Initialize performance metrics\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for features, targets in dataloader:\n            # Put the data and target to the device\n            features, targets = features.to(device), targets.to(device)\n\n            # Make predictions -- forward propagation\n            predictions = model(features)\n\n            # Calculate the loss\n            loss = loss_fn(predictions, targets)\n\n            # Track progress\n            running_loss += loss.item()\n            _, predicted = torch.max(predictions, 1)\n            total += targets.size(0)\n            correct += (predicted == targets).sum().item()\n\n    avg_loss = running_loss / len(dataloader)\n    accuracy = 100. * correct / total\n    return avg_loss, accuracy\n\ndef train_step(\n    model: nn.Module,\n    dataloader: DataLoader,\n    loss_fn: nn.Module,\n    optimizer: optim.Optimizer,\n    device: torch.device\n):\n    # Put the model in training mode\n    model.train()\n\n    # Initialize performance metrics\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for batch_idx, (features, targets) in enumerate(dataloader):\n        # Put the data and targets to the correct device\n        features, targets = features.to(device), targets.to(device)\n\n        # Reset the optimizer\n        optimizer.zero_grad()\n\n        # Make predictions\n        predictions = model(features)\n\n        # Calculate the loss\n        loss = loss_fn(predictions, targets)\n\n        # Calculate the adjustments\n        loss.backward()\n        \n        # Update the model\n        optimizer.step()\n\n        # Track progress\n        running_loss += loss.item()\n        _, predicted = torch.max(predictions, 1)\n        total += targets.size(0)\n        correct += (predicted == targets).sum().item()\n    \n    average_loss = running_loss / len(dataloader)\n    accuracy = 100. * correct / total\n    return average_loss, accuracy\n```\n:::\n\n\nNow train the model for several epochs on the training data, and after each epoch get the validation loss and accuracy.\n\n::: {#8f85608e .cell execution_count=5}\n``` {.python .cell-code}\nNUM_EPOCHS = 10\n\nhistory = {metric: [] for metric in [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\"]}\n\nfor epoch in range(NUM_EPOCHS):\n    train_loss, train_acc = train_step(model=baseline_model, dataloader=train_loader, loss_fn=loss_fn, optimizer=optimizer, device=device)\n    val_loss, val_acc = eval_step(model=baseline_model, dataloader=test_loader, loss_fn=loss_fn, device=device)\n    history[\"train_loss\"].append(train_loss)\n    history[\"train_acc\"].append(train_acc)\n    history[\"val_loss\"].append(val_loss)\n    history[\"val_acc\"].append(val_acc)\nprint(f\"Final validation accuracy: {history['val_acc'][-1]}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFinal validation accuracy: 95.48\n```\n:::\n:::\n\n\nWe have to check whether the training has converged and that we are not overfitting.\n\n::: {#29d9443c .cell execution_count=6}\n``` {.python .cell-code}\nfig, axs = plt.subplots(1, 2, sharex=True)\naxs[0].plot(np.arange(NUM_EPOCHS) + 1, history[\"train_loss\"], label=\"training\")\naxs[0].plot(np.arange(NUM_EPOCHS) + 1, history[\"val_loss\"], label=\"validation\")\naxs[1].plot(np.arange(NUM_EPOCHS) + 1, history[\"train_acc\"], label=\"training\")\naxs[1].plot(np.arange(NUM_EPOCHS) + 1, history[\"val_acc\"], label=\"validation\")\naxs[0].set_ylabel(\"Loss\")\naxs[0].legend(loc=\"upper right\")\naxs[1].set_ylabel(\"Accuracy\")\naxs[1].legend(loc=\"lower right\")\nfor ax in axs:\n    ax.set_xlabel(\"Epoch\")\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}